{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2204178-19c4-48fe-96b9-6dbbfe4f0f6c",
   "metadata": {},
   "source": [
    "# BLG-454E Learning From Data Term Project: Data Distillation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338520d6-ef89-4c75-bfc3-adcc95deae91",
   "metadata": {},
   "source": [
    "## Ã–mer Faruk San-150220307\n",
    "## Mustafa Kerem Bulut-150220303"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b5ee175-7f45-408a-94ba-e1e27d52af10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy # For deep copying models\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# For reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fab6a89-240f-4f2f-906f-57630f051d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Full training dataset size: 50000\n",
      "Test dataset size: 10000\n"
     ]
    }
   ],
   "source": [
    "# CIFAR-10 constants\n",
    "IMG_SIZE = 32\n",
    "N_CHANNELS = 3\n",
    "N_CLASSES = 10\n",
    "\n",
    "# Data preprocessing\n",
    "# For CIFAR-10, the mean and std are standard values.\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(IMG_SIZE, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# Load datasets\n",
    "train_dataset_full = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "# DataLoaders\n",
    "batch_size_real = 128 # Batch size for training on real data\n",
    "train_loader_full = DataLoader(train_dataset_full, batch_size=batch_size_real, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f\"Full training dataset size: {len(train_dataset_full)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")\n",
    "\n",
    "# Function to display images (optional, for verification)\n",
    "def imshow(img_tensor, title=None):\n",
    "    img_tensor = img_tensor.cpu() / 2 + 0.5  # Unnormalize (approximate)\n",
    "    npimg = img_tensor.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# Example: Get some random training images\n",
    "dataiter = iter(train_loader_full)\n",
    "images, labels = next(dataiter)\n",
    "# imshow(torchvision.utils.make_grid(images[:4])) # Requires torchvision\n",
    "# print(' '.join(f'{train_dataset_full.classes[labels[j]]:5s}' for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e65eec8-ee6d-41fb-bf49-4b19f55a0cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, num_classes=N_CLASSES):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(N_CHANNELS, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2) # 32x32 -> 16x16\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.conv4 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(128)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2) # 16x16 -> 8x8\n",
    "        self.fc1 = nn.Linear(128 * 8 * 8, 512)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = self.pool2(x)\n",
    "        x = x.view(-1, 128 * 8 * 8)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model and move to device\n",
    "# For now, this is our \"teacher_model_architecture\" and also \"student_model_architecture\"\n",
    "model_architecture = ConvNet \n",
    "\n",
    "# Example:\n",
    "# model = model_architecture(num_classes=N_CLASSES).to(device)\n",
    "# summary(model, (N_CHANNELS, IMG_SIZE, IMG_SIZE)) # Requires torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57ad7bf4-3eb4-4f6d-b6e5-2e19d0df0a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Teacher Model Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ab9908304bb4126a887c994cd7d3417",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53579918a6e44d1aaeff0769f1da8d88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher Epoch 1/15:\n",
      "  Train Loss: 1.6088, Train Acc: 0.4061\n",
      "  Test Loss: 1.3629, Test Acc: 0.4871\n",
      "  LR: 0.009891\n",
      "  Saved parameters to trajectory at epoch 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddb9791dcf604c509f7ed2c1264ddd2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23fbbaa4bf18437e8bac92a2e36f4e15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher Epoch 2/15:\n",
      "  Train Loss: 1.2846, Train Acc: 0.5372\n",
      "  Test Loss: 1.1631, Test Acc: 0.5857\n",
      "  LR: 0.009568\n",
      "  Saved parameters to trajectory at epoch 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82aecd9fb0e74167858529e069146060",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abb0f8eabb6b4e7daf5efa79c6a48368",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher Epoch 3/15:\n",
      "  Train Loss: 1.1049, Train Acc: 0.6067\n",
      "  Test Loss: 1.0334, Test Acc: 0.6523\n",
      "  LR: 0.009045\n",
      "  Saved parameters to trajectory at epoch 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ac27b24827149778479854924d7d51c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eabb63a24b1a4382ba85276bb346f5e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher Epoch 4/15:\n",
      "  Train Loss: 0.9994, Train Acc: 0.6469\n",
      "  Test Loss: 0.7971, Test Acc: 0.7197\n",
      "  LR: 0.008346\n",
      "  Saved parameters to trajectory at epoch 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4b707a833634d3cb47ca1b1369b428f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf506f9a30cc4aa897fa307f7bdd17d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher Epoch 5/15:\n",
      "  Train Loss: 0.9218, Train Acc: 0.6777\n",
      "  Test Loss: 0.7937, Test Acc: 0.7226\n",
      "  LR: 0.007500\n",
      "  Saved parameters to trajectory at epoch 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ea2913f62ae484f8bd24b471c1b93d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "260a6cecadff4820bf858675ed365527",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher Epoch 6/15:\n",
      "  Train Loss: 0.8448, Train Acc: 0.7039\n",
      "  Test Loss: 0.7413, Test Acc: 0.7434\n",
      "  LR: 0.006545\n",
      "  Saved parameters to trajectory at epoch 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8bbbbfb21eb4e94a328a08d97f9ac0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84b290743c404ff4b08539ddfbc743a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher Epoch 7/15:\n",
      "  Train Loss: 0.7953, Train Acc: 0.7216\n",
      "  Test Loss: 0.6747, Test Acc: 0.7661\n",
      "  LR: 0.005523\n",
      "  Saved parameters to trajectory at epoch 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ced915393266444080973a68c398f51d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62624e0fc4ed4c0ab6b6c13e6e2f4fa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher Epoch 8/15:\n",
      "  Train Loss: 0.7411, Train Acc: 0.7400\n",
      "  Test Loss: 0.5924, Test Acc: 0.7978\n",
      "  LR: 0.004477\n",
      "  Saved parameters to trajectory at epoch 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d37be1a41e9a4cb284cee2469e4c93c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b7c1bc2392843a08773d585112ecac3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher Epoch 9/15:\n",
      "  Train Loss: 0.6993, Train Acc: 0.7577\n",
      "  Test Loss: 0.5765, Test Acc: 0.8018\n",
      "  LR: 0.003455\n",
      "  Saved parameters to trajectory at epoch 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e95bece2ea34c61b2631eff9ac4ac40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "585453e3b3b54578a34e2ee19c7e58ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher Epoch 10/15:\n",
      "  Train Loss: 0.6646, Train Acc: 0.7702\n",
      "  Test Loss: 0.5724, Test Acc: 0.8022\n",
      "  LR: 0.002500\n",
      "  Saved parameters to trajectory at epoch 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8696bbe158fc4a11b346a2fa5b9822a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a26fac15ad4c43e183e0c1cb88f83911",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher Epoch 11/15:\n",
      "  Train Loss: 0.6373, Train Acc: 0.7811\n",
      "  Test Loss: 0.5352, Test Acc: 0.8131\n",
      "  LR: 0.001654\n",
      "  Saved parameters to trajectory at epoch 11\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b509ab4142784ec09433bad9513b330b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c92ae765652347508066fa18a7cdd807",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher Epoch 12/15:\n",
      "  Train Loss: 0.5978, Train Acc: 0.7932\n",
      "  Test Loss: 0.5189, Test Acc: 0.8192\n",
      "  LR: 0.000955\n",
      "  Saved parameters to trajectory at epoch 12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66cfc8da960a492099e0ea74b0b830f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa18bd1b9d2a4535910504db5162641f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher Epoch 13/15:\n",
      "  Train Loss: 0.5789, Train Acc: 0.7993\n",
      "  Test Loss: 0.5117, Test Acc: 0.8228\n",
      "  LR: 0.000432\n",
      "  Saved parameters to trajectory at epoch 13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a6d43806b1e45e19b953eda7a4d9cd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db642ba782994954ae101ffbf048b027",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher Epoch 14/15:\n",
      "  Train Loss: 0.5651, Train Acc: 0.8047\n",
      "  Test Loss: 0.4916, Test Acc: 0.8290\n",
      "  LR: 0.000109\n",
      "  Saved parameters to trajectory at epoch 14\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2434f7315c944b6d91274e2e96de8579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f69b99c4b4d24d3eaaf9eab4a77f3bd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher Epoch 15/15:\n",
      "  Train Loss: 0.5531, Train Acc: 0.8104\n",
      "  Test Loss: 0.4867, Test Acc: 0.8301\n",
      "  LR: 0.000000\n",
      "  Saved parameters to trajectory at epoch 15\n",
      "\n",
      "Teacher model saved to teacher_model.pth\n",
      "Teacher trajectory (len: 15) saved to teacher_trajectory.pth\n"
     ]
    }
   ],
   "source": [
    "# --- Configuration for Baseline Teacher Training ---\n",
    "teacher_epochs = 15 # Number of epochs to train the teacher model\n",
    "lr_teacher = 0.01\n",
    "momentum_teacher = 0.9\n",
    "weight_decay_teacher = 5e-4\n",
    "# Trajectory saving: Save parameters at the end of these specific epochs\n",
    "# This makes the trajectory shorter and easier to handle initially.\n",
    "# The paper matches trajectories over a few steps (e.g. 10-20 inner loop steps for student)\n",
    "# We might need to save parameters more frequently if we want to match short trajectories.\n",
    "# Let's start by saving at the end of each epoch for a few epochs.\n",
    "# TRAJECTORY_SAVE_EPOCHS = [0, 1, 2, 3, 4, 9, 19, 29, 39, 49] # Example: save at these epochs\n",
    "TRAJECTORY_SAVE_EPOCHS = list(range(teacher_epochs)) # Save at the end of every epoch for now\n",
    "\n",
    "# Path to save teacher model and trajectory\n",
    "TEACHER_MODEL_PATH = \"teacher_model.pth\"\n",
    "TEACHER_TRAJECTORY_PATH = \"teacher_trajectory.pth\"\n",
    "\n",
    "# --- Helper function for training one epoch ---\n",
    "def train_epoch(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for inputs, labels in tqdm(dataloader, desc=\"Training Epoch\", leave=False):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_samples += labels.size(0)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / total_samples\n",
    "    epoch_acc = correct_predictions / total_samples\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "# --- Helper function for evaluating the model ---\n",
    "def evaluate_model(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(dataloader, desc=\"Evaluating\", leave=False):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_samples += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / total_samples\n",
    "    epoch_acc = correct_predictions / total_samples\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "# --- Train the Teacher Model and Save Trajectory ---\n",
    "teacher_model = model_architecture(num_classes=N_CLASSES).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_teacher = optim.SGD(teacher_model.parameters(), lr=lr_teacher, momentum=momentum_teacher, weight_decay=weight_decay_teacher)\n",
    "# Optional: Learning rate scheduler\n",
    "scheduler_teacher = optim.lr_scheduler.CosineAnnealingLR(optimizer_teacher, T_max=teacher_epochs)\n",
    "\n",
    "teacher_trajectory = [] # List to store model parameters at specified points\n",
    "\n",
    "print(\"Starting Teacher Model Training...\")\n",
    "\n",
    "# Initial state before training (optional, but often epoch 0 means after 1st epoch)\n",
    "# If you want to match from the *very first* random initialization, save here.\n",
    "# For simplicity, Cazenavette et al. often re-initialize student networks for each outer loop step.\n",
    "# Let's save after the first epoch (epoch 0).\n",
    "\n",
    "for epoch in range(teacher_epochs):\n",
    "    epoch_train_loss, epoch_train_acc = train_epoch(teacher_model, train_loader_full, optimizer_teacher, criterion, device)\n",
    "    scheduler_teacher.step() # Update learning rate\n",
    "\n",
    "    # Evaluate on test set (optional during teacher training, but good for monitoring)\n",
    "    epoch_test_loss, epoch_test_acc = evaluate_model(teacher_model, test_loader, criterion, device)\n",
    "\n",
    "    print(f\"Teacher Epoch {epoch+1}/{teacher_epochs}:\")\n",
    "    print(f\"  Train Loss: {epoch_train_loss:.4f}, Train Acc: {epoch_train_acc:.4f}\")\n",
    "    print(f\"  Test Loss: {epoch_test_loss:.4f}, Test Acc: {epoch_test_acc:.4f}\")\n",
    "    print(f\"  LR: {optimizer_teacher.param_groups[0]['lr']:.6f}\")\n",
    "\n",
    "\n",
    "    # Save model parameters for the trajectory\n",
    "    if epoch in TRAJECTORY_SAVE_EPOCHS:\n",
    "        # We need to save a deep copy of the state_dict, otherwise it's just a reference\n",
    "        # and will change as the model continues to train.\n",
    "        trajectory_point = {k: v.detach().clone().cpu() for k, v in teacher_model.state_dict().items()}\n",
    "        teacher_trajectory.append(trajectory_point)\n",
    "        print(f\"  Saved parameters to trajectory at epoch {epoch+1}\")\n",
    "\n",
    "# Save the final teacher model\n",
    "torch.save(teacher_model.state_dict(), TEACHER_MODEL_PATH)\n",
    "print(f\"\\nTeacher model saved to {TEACHER_MODEL_PATH}\")\n",
    "\n",
    "# Save the trajectory\n",
    "torch.save(teacher_trajectory, TEACHER_TRAJECTORY_PATH)\n",
    "print(f\"Teacher trajectory (len: {len(teacher_trajectory)}) saved to {TEACHER_TRAJECTORY_PATH}\")\n",
    "\n",
    "# Verify saved trajectory (optional)\n",
    "# loaded_trajectory = torch.load(TEACHER_TRAJECTORY_PATH)\n",
    "# print(f\"Loaded trajectory length: {len(loaded_trajectory)}\")\n",
    "# print(f\"Keys in first trajectory point: {loaded_trajectory[0].keys()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5fafcb8-b2c4-4d73-a32f-1215b0d6bd80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized X_syn with shape: torch.Size([100, 3, 32, 32])\n",
      "Shape of X_syn: torch.Size([100, 3, 32, 32])\n",
      "Shape of Y_syn: torch.Size([100])\n",
      "Sample Y_syn: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7,\n",
      "        7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9,\n",
      "        9, 9, 9, 9], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# --- Configuration for Synthetic Dataset ---\n",
    "IPC = 10 # Images Per Class, as per your proposal\n",
    "TOTAL_SYNTHETIC_IMAGES = IPC * N_CLASSES\n",
    "\n",
    "# --- Initialize Synthetic Data ---\n",
    "\n",
    "# Initialize Synthetic Images (X_syn)\n",
    "# Option 1: Random Noise\n",
    "# X_syn_init_data = torch.randn(TOTAL_SYNTHETIC_IMAGES, N_CHANNELS, IMG_SIZE, IMG_SIZE, device=device)\n",
    "\n",
    "# Option 2: From Real Images (often preferred as a starting point)\n",
    "# We'll select IPC images from each class from the original training set.\n",
    "def initialize_synthetic_images_from_real(train_dataset, num_classes, ipc, img_size, n_channels):\n",
    "    \"\"\"\n",
    "    Initializes synthetic images by picking IPC images from each class\n",
    "    from the real dataset.\n",
    "    \"\"\"\n",
    "    X_syn_list = []\n",
    "    Y_syn_list = []\n",
    "    \n",
    "    # Create a temporary dataloader to iterate by class easily (if not already structured that way)\n",
    "    # Alternatively, iterate through the dataset and collect indices per class\n",
    "    class_indices = [[] for _ in range(num_classes)]\n",
    "    for i, (_, label) in enumerate(train_dataset):\n",
    "        if len(class_indices[label]) < ipc:\n",
    "            class_indices[label].append(i)\n",
    "        # Optimization: if all classes have enough samples, break\n",
    "        if all(len(indices) == ipc for indices in class_indices):\n",
    "            break\n",
    "            \n",
    "    if not all(len(indices) == ipc for indices in class_indices):\n",
    "        print(\"Warning: Could not find enough unique images for all classes to initialize synthetic data.\")\n",
    "        # Fallback or error handling needed if a class has < IPC samples, though unlikely for CIFAR-10.\n",
    "\n",
    "    for c in range(num_classes):\n",
    "        indices_c = class_indices[c][:ipc] # Take the first ipc indices for class c\n",
    "        for idx in indices_c:\n",
    "            img, label = train_dataset[idx] # img is already transformed\n",
    "            X_syn_list.append(img)\n",
    "            Y_syn_list.append(torch.tensor(label)) # Store label as tensor\n",
    "\n",
    "    X_syn_init_data = torch.stack(X_syn_list).to(device)\n",
    "    # Y_syn will be fixed based on this initialization order, or we can create it explicitly\n",
    "    \n",
    "    print(f\"Initialized X_syn with shape: {X_syn_init_data.shape}\")\n",
    "    return X_syn_init_data\n",
    "\n",
    "# Choose initialization method:\n",
    "INIT_METHOD = 'real' # 'random' or 'real'\n",
    "\n",
    "if INIT_METHOD == 'real':\n",
    "    # We need the original train_dataset *without* on-the-fly random augmentations\n",
    "    # for consistent initialization if we run this multiple times.\n",
    "    # The transform_test is suitable here as it only does ToTensor and Normalize.\n",
    "    train_dataset_for_init = datasets.CIFAR10(root='./data', train=True, download=False, transform=transform_test)\n",
    "    X_syn_data = initialize_synthetic_images_from_real(train_dataset_for_init, N_CLASSES, IPC, IMG_SIZE, N_CHANNELS)\n",
    "else: # 'random'\n",
    "    X_syn_data = torch.randn(TOTAL_SYNTHETIC_IMAGES, N_CHANNELS, IMG_SIZE, IMG_SIZE, device=device)\n",
    "    # For random init, you might want to scale it to a typical image range or normalize later.\n",
    "    # For now, raw randn output.\n",
    "\n",
    "# These synthetic images are the parameters we want to learn.\n",
    "# So, they need to require gradients.\n",
    "X_syn = X_syn_data.detach().clone().requires_grad_(True)\n",
    "# X_syn.data.clamp_(0, 1) # Optional: clamp if you initialized randomly and want to keep in [0,1] before normalization\n",
    "                         # If initialized from real (normalized) data, this might not be needed or done differently.\n",
    "                         # Since CIFAR-10 is normalized around 0, clamping to [0,1] is not directly applicable here\n",
    "                         # unless you unnormalize first. For now, let's assume it's fine.\n",
    "\n",
    "# Initialize Synthetic Labels (Y_syn)\n",
    "# These are typically fixed and not learned.\n",
    "# Create labels: IPC images for class 0, then IPC for class 1, etc.\n",
    "y_syn_list = []\n",
    "for c in range(N_CLASSES):\n",
    "    y_syn_list.extend([c] * IPC)\n",
    "Y_syn = torch.tensor(y_syn_list, dtype=torch.long, device=device)\n",
    "\n",
    "print(f\"Shape of X_syn: {X_syn.shape}\") # Should be [100, 3, 32, 32]\n",
    "print(f\"Shape of Y_syn: {Y_syn.shape}\") # Should be [100]\n",
    "print(f\"Sample Y_syn: {Y_syn}\")\n",
    "\n",
    "# Optimizer for the synthetic data (X_syn) itself\n",
    "# This is the \"outer loop\" optimizer\n",
    "lr_syn = 1.0 # Learning rate for updating synthetic images. This is a key hyperparameter!\n",
    "             # Some papers use much smaller LRs like 0.001 or 0.01, depends on the loss scale.\n",
    "             # Cazenavette et al. use Adam with lr=0.1 for X_syn.\n",
    "optimizer_X_syn = optim.Adam([X_syn], lr=lr_syn)\n",
    "# optimizer_X_syn = optim.SGD([X_syn], lr=lr_syn, momentum=0.5) # Another option\n",
    "\n",
    "# We might also want to learn per-sample learning rates or other parameters,\n",
    "# but let's start with just learning X_syn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35555cda-8f1c-44dc-bcaa-e91705404802",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'optim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      4\u001b[39m lr_student_inner = \u001b[32m0.01\u001b[39m     \u001b[38;5;66;03m# LR for student model training on X_syn\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# lr_syn was defined in Step 4 for optimizer_X_syn (e.g., Adam with lr=0.1 or SGD with lr=1.0)\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Re-confirm optimizer_X_syn from Step 4. If you used SGD there, lr_syn=1.0 might be okay to start.\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# If Adam, lr_syn=0.1 is more common. Let's assume Adam as per Cazenavette et al. for X_syn.\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# If optimizer_X_syn was SGD(lr=1.0), you might need to adjust.\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Re-define optimizer_X_syn here for clarity or if you want to change it.\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Assuming X_syn is already defined and requires_grad=True from Step 4.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m optimizer_X_syn = \u001b[43moptim\u001b[49m.Adam([X_syn], lr=\u001b[32m0.1\u001b[39m, betas=(\u001b[32m0.5\u001b[39m, \u001b[32m0.999\u001b[39m)) \u001b[38;5;66;03m# Common choice from papers\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Load teacher trajectory (ensure this was saved successfully in Step 3)\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mNameError\u001b[39m: name 'optim' is not defined"
     ]
    }
   ],
   "source": [
    "# --- Configuration for Distillation Loop ---\n",
    "distill_epochs = 1000       # Number of outer loop optimization steps for X_syn\n",
    "student_inner_steps = 10    # Number of SGD steps to train student on X_syn in each outer step\n",
    "lr_student_inner = 0.01     # LR for student model training on X_syn\n",
    "# lr_syn was defined in Step 4 for optimizer_X_syn (e.g., Adam with lr=0.1 or SGD with lr=1.0)\n",
    "# Re-confirm optimizer_X_syn from Step 4. If you used SGD there, lr_syn=1.0 might be okay to start.\n",
    "# If Adam, lr_syn=0.1 is more common. Let's assume Adam as per Cazenavette et al. for X_syn.\n",
    "# If optimizer_X_syn was SGD(lr=1.0), you might need to adjust.\n",
    "# Re-define optimizer_X_syn here for clarity or if you want to change it.\n",
    "# Assuming X_syn is already defined and requires_grad=True from Step 4.\n",
    "optimizer_X_syn = optim.Adam([X_syn], lr=0.1, betas=(0.5, 0.999)) # Common choice from papers\n",
    "\n",
    "# Load teacher trajectory (ensure this was saved successfully in Step 3)\n",
    "try:\n",
    "    teacher_trajectory = torch.load(TEACHER_TRAJECTORY_PATH, map_location=torch.device('cpu')) # Load to CPU first\n",
    "    print(f\"Loaded teacher trajectory with {len(teacher_trajectory)} points.\")\n",
    "    if not teacher_trajectory: # Empty list\n",
    "        raise FileNotFoundError\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Teacher trajectory not found or empty at {TEACHER_TRAJECTORY_PATH}. Please run Step 3 first.\")\n",
    "    # For notebooks, you might want to raise an error to stop execution\n",
    "    # For scripts, sys.exit() or raise is appropriate.\n",
    "    raise SystemExit(\"Teacher trajectory missing or empty.\")\n",
    "\n",
    "\n",
    "# Criterion for student training (already defined as `criterion` global)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(\"\\nStarting Dataset Distillation Loop...\")\n",
    "if not X_syn.is_leaf or not X_syn.requires_grad:\n",
    "     print(\"Warning: X_syn is not a leaf tensor or does not require gradients!\")\n",
    "     X_syn.requires_grad_(True) # Ensure it does\n",
    "\n",
    "for epoch_distill in tqdm(range(distill_epochs), desc=\"Distillation Epochs\"):\n",
    "    optimizer_X_syn.zero_grad()\n",
    "\n",
    "    # 1. Initialize Student Model and Select Teacher States\n",
    "    student_model = model_architecture(num_classes=N_CLASSES).to(device)\n",
    "    \n",
    "    # Pick a starting point from the teacher trajectory\n",
    "    teacher_idx_start = epoch_distill % len(teacher_trajectory)\n",
    "    teacher_start_params_cpu = teacher_trajectory[teacher_idx_start]\n",
    "    \n",
    "    # Load these params into the student model.\n",
    "    student_model.load_state_dict({k: v.clone().to(device) for k, v in teacher_start_params_cpu.items()})\n",
    "\n",
    "    # Student model requires its own optimizer for the inner loop\n",
    "    optimizer_student = optim.SGD(student_model.parameters(), lr=lr_student_inner, momentum=0.5)\n",
    "\n",
    "    # 2. Train Student Model on current X_syn for `student_inner_steps`\n",
    "    for _inner_step in range(student_inner_steps):\n",
    "        outputs_student = student_model(X_syn) # X_syn is used here\n",
    "        loss_student = criterion(outputs_student, Y_syn)\n",
    "        \n",
    "        optimizer_student.zero_grad()\n",
    "        loss_student.backward() \n",
    "        optimizer_student.step()\n",
    "\n",
    "    # 3. Select Teacher Target Parameters\n",
    "    if len(teacher_trajectory) == 1:\n",
    "        teacher_idx_target = teacher_idx_start\n",
    "    else:\n",
    "        teacher_idx_target = (teacher_idx_start + 1) % len(teacher_trajectory)\n",
    "    teacher_target_params_cpu = teacher_trajectory[teacher_idx_target]\n",
    "    \n",
    "    # ////////////////////////////////////////////////////////////////////////\n",
    "    # /// START OF REVISED META-LOSS CALCULATION ///\n",
    "    # ////////////////////////////////////////////////////////////////////////\n",
    "    \n",
    "    # 4. Calculate Trajectory Matching Loss (Meta-Loss)\n",
    "    meta_loss_components = []\n",
    "    \n",
    "    # Prepare teacher target parameters on the correct device for easy lookup\n",
    "    teacher_target_params_dict_device = {k: v.clone().to(device) for k, v in teacher_target_params_cpu.items()}\n",
    "\n",
    "    # Iterate through the student model's named parameters.\n",
    "    # These parameters were updated in the inner loop and have grad_fns linking back to X_syn.\n",
    "    for name, param_student in student_model.named_parameters():\n",
    "        if param_student.requires_grad: # Only consider learnable parameters\n",
    "            if name in teacher_target_params_dict_device:\n",
    "                param_teacher_target = teacher_target_params_dict_device[name]\n",
    "                # param_teacher_target is detached (from trajectory)\n",
    "                # param_student has a grad_fn from the inner loop\n",
    "                loss_component = torch.sum((param_student - param_teacher_target)**2)\n",
    "                meta_loss_components.append(loss_component)\n",
    "            else:\n",
    "                # This should ideally not happen if architectures are identical\n",
    "                # and state_dicts are complete.\n",
    "                print(f\"Warning during meta-loss: Student parameter '{name}' not found in teacher target parameters. Skipping.\")\n",
    "    \n",
    "    if not meta_loss_components:\n",
    "        print(f\"CRITICAL Error at Distill Epoch {epoch_distill}: No components found for meta_loss. Meta-loss will be zero.\")\n",
    "        print(f\"  Teacher start idx: {teacher_idx_start}, Teacher target idx: {teacher_idx_target}\")\n",
    "        print(f\"  Number of student_model.named_parameters(): {len(list(student_model.named_parameters()))}\")\n",
    "        print(f\"  Number of teacher_target_params_dict_device keys: {len(teacher_target_params_dict_device.keys())}\")\n",
    "        # This is a fallback, but indicates a serious issue if it happens.\n",
    "        meta_loss = torch.tensor(0.0, device=device, requires_grad=True) \n",
    "    else:\n",
    "        meta_loss = torch.stack(meta_loss_components).sum()\n",
    "        \n",
    "\n",
    "    # 5. Backpropagate Meta-Loss and Update X_syn\n",
    "    meta_loss.backward()\n",
    "    optimizer_X_syn.step()\n",
    "    \n",
    "    if epoch_distill % 50 == 0 or epoch_distill == distill_epochs - 1 :\n",
    "        print(f\"Distill Epoch {epoch_distill+1}/{distill_epochs}, Meta Loss: {meta_loss.item():.4f}\")\n",
    "        # print(f\"  X_syn stats: min={X_syn.min().item():.4f}, max={X_syn.max().item():.4f}, mean={X_syn.mean().item():.4f}\")\n",
    "\n",
    "# --- End of Distillation Loop ---\n",
    "\n",
    "distilled_data_path = 'distilled_dataset_final.pth'\n",
    "torch.save({'X_syn': X_syn.detach().cpu(), \n",
    "            'Y_syn': Y_syn.cpu(),\n",
    "            'N_CLASSES': N_CLASSES,\n",
    "            'IPC': IPC}, \n",
    "            distilled_data_path)\n",
    "print(f\"Final distilled dataset saved to {distilled_data_path}\")\n",
    "\n",
    "# --- Optional: Visualize some final synthetic images ---\n",
    "# (Visualization code would go here, same as before)\n",
    "# Define MEAN_CIFAR and STD_CIFAR if you haven't globally\n",
    "MEAN_CIFAR = torch.tensor([0.4914, 0.4822, 0.4465], device='cpu').view(1, 3, 1, 1)\n",
    "STD_CIFAR = torch.tensor([0.2023, 0.1994, 0.2010], device='cpu').view(1, 3, 1, 1)\n",
    "\n",
    "X_syn_to_show = X_syn.detach().cpu()\n",
    "# Ensure X_syn_to_show has the same channel order as MEAN/STD if needed for broadcasting\n",
    "# Assuming X_syn_to_show is [N, C, H, W]\n",
    "X_syn_unnormalized = X_syn_to_show * STD_CIFAR + MEAN_CIFAR # Unnormalize\n",
    "X_syn_unnormalized = torch.clamp(X_syn_unnormalized, 0, 1) # Clamp to valid image range\n",
    "\n",
    "fig, axes = plt.subplots(N_CLASSES, IPC, figsize=(IPC * 1.2, N_CLASSES * 1.2))\n",
    "if N_CLASSES == 1 and IPC == 1: # Handle single image case\n",
    "    axes = np.array([[axes]])\n",
    "elif N_CLASSES == 1: \n",
    "    axes = axes.reshape(1, IPC)\n",
    "elif IPC == 1: \n",
    "    axes = axes.reshape(N_CLASSES, 1)\n",
    "\n",
    "\n",
    "for i_class in range(N_CLASSES):\n",
    "    for j_ipc in range(IPC):\n",
    "        idx = i_class * IPC + j_ipc\n",
    "        if idx < X_syn_unnormalized.shape[0]:\n",
    "            img = X_syn_unnormalized[idx]\n",
    "            current_ax = axes[i_class, j_ipc]\n",
    "            current_ax.imshow(img.permute(1, 2, 0).numpy()) # CHW to HWC for matplotlib\n",
    "            current_ax.axis('off')\n",
    "            if j_ipc == 0: # Add class label to the first image of each row\n",
    "                current_ax.set_title(f\"C{i_class}\", fontsize=8) # Using train_dataset_full.classes[i_class] would be better if available\n",
    "\n",
    "plt.suptitle(f\"Distilled Images (End of Distillation)\", fontsize=10)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96]) # Adjust for suptitle\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6ffe7ba-3a26-4012-b024-9a75f76c6e46",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'IPC' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m eval_epochs_on_distilled = \u001b[32m200\u001b[39m \u001b[38;5;66;03m# Number of epochs to train a NEW model on the distilled set\u001b[39;00m\n\u001b[32m      3\u001b[39m lr_eval = \u001b[32m0.01\u001b[39m                 \u001b[38;5;66;03m# Learning rate for training on distilled set\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m batch_size_distilled = \u001b[38;5;28mmin\u001b[39m(\u001b[43mIPC\u001b[49m * N_CLASSES, \u001b[32m100\u001b[39m) \u001b[38;5;66;03m# Use all 100 images in a batch, or smaller if preferred\u001b[39;00m\n\u001b[32m      5\u001b[39m                                               \u001b[38;5;66;03m# For 100 images, full-batch GD is feasible.\u001b[39;00m\n\u001b[32m      6\u001b[39m \n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# --- Load the Distilled Dataset ---\u001b[39;00m\n\u001b[32m      8\u001b[39m distilled_data_path = \u001b[33m'\u001b[39m\u001b[33mdistilled_dataset_final.pth\u001b[39m\u001b[33m'\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m: name 'IPC' is not defined"
     ]
    }
   ],
   "source": [
    "# --- Configuration for Evaluating Distilled Dataset ---\n",
    "eval_epochs_on_distilled = 200 # Number of epochs to train a NEW model on the distilled set\n",
    "lr_eval = 0.01                 # Learning rate for training on distilled set\n",
    "batch_size_distilled = min(IPC * N_CLASSES, 100) # Use all 100 images in a batch, or smaller if preferred\n",
    "                                              # For 100 images, full-batch GD is feasible.\n",
    "\n",
    "# --- Load the Distilled Dataset ---\n",
    "distilled_data_path = 'distilled_dataset_final.pth'\n",
    "try:\n",
    "    saved_data = torch.load(distilled_data_path)\n",
    "    X_syn_final = saved_data['X_syn'].to(device) # Move to device for training\n",
    "    Y_syn_final = saved_data['Y_syn'].to(device) # Move to device\n",
    "    N_CLASSES_loaded = saved_data['N_CLASSES']\n",
    "    IPC_loaded = saved_data['IPC']\n",
    "    print(f\"Loaded distilled dataset: X_syn shape {X_syn_final.shape}, Y_syn shape {Y_syn_final.shape}\")\n",
    "    assert N_CLASSES_loaded == N_CLASSES\n",
    "    assert IPC_loaded == IPC\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Distilled dataset not found at {distilled_data_path}. Please run Step 5 first.\")\n",
    "    raise SystemExit(\"Distilled dataset missing.\")\n",
    "\n",
    "# Create DataLoader for the distilled dataset\n",
    "distilled_dataset = TensorDataset(X_syn_final, Y_syn_final)\n",
    "distilled_loader = DataLoader(distilled_dataset, batch_size=batch_size_distilled, shuffle=True)\n",
    "\n",
    "# --- Initialize and Train a New Model on the Distilled Dataset ---\n",
    "eval_model = model_architecture(num_classes=N_CLASSES).to(device) # Fresh model\n",
    "criterion_eval = nn.CrossEntropyLoss() # Same criterion as before\n",
    "optimizer_eval = optim.SGD(eval_model.parameters(), lr=lr_eval, momentum=0.9, weight_decay=5e-4) # Standard SGD\n",
    "# Optional: Learning rate scheduler for this evaluation training\n",
    "# scheduler_eval = optim.lr_scheduler.CosineAnnealingLR(optimizer_eval, T_max=eval_epochs_on_distilled)\n",
    "scheduler_eval = optim.lr_scheduler.MultiStepLR(optimizer_eval, milestones=[int(0.5*eval_epochs_on_distilled), int(0.75*eval_epochs_on_distilled)], gamma=0.1)\n",
    "\n",
    "\n",
    "print(\"\\nStarting Evaluation: Training a new model on the distilled dataset...\")\n",
    "for epoch_eval in tqdm(range(eval_epochs_on_distilled), desc=\"Eval Epochs on Distilled Data\"):\n",
    "    eval_model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    # Since the distilled dataset is small, one epoch might just be one batch if batch_size_distilled is large enough.\n",
    "    for inputs_syn, labels_syn in distilled_loader: # inputs_syn and labels_syn are already on device\n",
    "        optimizer_eval.zero_grad()\n",
    "        outputs = eval_model(inputs_syn)\n",
    "        loss = criterion_eval(outputs, labels_syn)\n",
    "        loss.backward()\n",
    "        optimizer_eval.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs_syn.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_samples += labels_syn.size(0)\n",
    "        correct_predictions += (predicted == labels_syn).sum().item()\n",
    "    \n",
    "    scheduler_eval.step()\n",
    "\n",
    "    epoch_train_loss = running_loss / total_samples\n",
    "    epoch_train_acc = correct_predictions / total_samples\n",
    "\n",
    "    # Evaluate on the *real* CIFAR-10 test set\n",
    "    # The `evaluate_model` function was defined in Step 3\n",
    "    # def evaluate_model(model, dataloader, criterion, device): ...\n",
    "    epoch_test_loss, epoch_test_acc = evaluate_model(eval_model, test_loader, criterion_eval, device)\n",
    "    \n",
    "    if (epoch_eval + 1) % 20 == 0 or epoch_eval == eval_epochs_on_distilled - 1:\n",
    "        print(f\"Eval Epoch {epoch_eval+1}/{eval_epochs_on_distilled}:\")\n",
    "        print(f\"  Train Loss (on distilled): {epoch_train_loss:.4f}, Train Acc (on distilled): {epoch_train_acc:.4f}\")\n",
    "        print(f\"  Test Loss (on CIFAR-10 test): {epoch_test_loss:.4f}, Test Acc (on CIFAR-10 test): {epoch_test_acc:.4f}\")\n",
    "        print(f\"  LR: {optimizer_eval.param_groups[0]['lr']:.6f}\")\n",
    "\n",
    "\n",
    "# Final performance on the test set\n",
    "final_test_loss, final_test_acc = evaluate_model(eval_model, test_loader, criterion_eval, device)\n",
    "print(\"\\n--- Evaluation Complete ---\")\n",
    "print(f\"Final Test Accuracy of model trained on distilled data: {final_test_acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65baaa0-f1d2-493c-b272-9531682341d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
